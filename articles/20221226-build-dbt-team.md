---
title: "dbt を使ったデータマネジメントと adhoc クエリの共存" # 記事のタイトル
emoji: "📈" # アイキャッチとして使われる絵文字（1文字だけ）
type: "idea" # tech: 技術記事 / idea: アイデア記事
topics: ["dbt","analytics","SQL"] # タグ。["markdown", "rust", "aws"]のように指定する
published: false # 公開設定（falseにすると下書き）
---

## 背景
- 既存の分析環境: argo と dbt でパイプラインを作った。層も分けたしモデリングもした。これから作られるモデルはデータマネジメントの効いた高品質なデータになるのだ。
- 世の中にある分析要件: ABテストのような短期のものが多い。今日思いついたクエリを本番環境で動かしたい。しかもデータは常に最新のものが欲しい。

このギャップを埋めたい。

## 考えたこと

dbt で綺麗なモデリングができるのはいい。
しかし、モデリング設計には時間がかかる。今欲しいデータがある。
それに、アドホックな運用を禁止したところで、エクセルやアクセスで数値が算出され、それが運用される未来に変わりはない。
ならば、多少荒っぽくても、リポジトリにコミットされ、一度でもレビューできていて、dbtでリネージがたどれるだけで良い。

限定されたユースケースで、うまくQCDのバランスを取る方法を考えたい

### 想定するユースケース
- 分析した結果が内部でのみ利用される
- 新規事業やF/Sで始めたABテストの初速結果を振り返るなど、正確さよりもスピードが求められる状況
- 分析結果だけを完全に信じるわけではなく、あくまでも参考値として扱い、他の定性分析党を組み合わせて事業判断がなされる

### 求める要件

今日かいたクエリを今日リリースできることとは以下のような感じ

- リリースのタイミングを自由に決められること
- SQLしかかけない人でも最新のデータを揃えたデータマートを作れること
- CI/CDのビルド時間が30分未満であること

# やったこと
## 仕組み
- モノリポ、モノプロジェクト
dbt のリネージをたどれる状態とするため + コードの置き場所を一つにするため

- デプロイフローの切り出し
通常は main push で dev 環境へのデプロイ、release tag で prd 環境へのデプロイとするところ、adhoc クエリのみ main push で prd 環境へのデプロイとした。
dev 環境へのデプロイ省略に加え、tag を打たないため差分のみがデプロイされるため、CI時間を大きく削減している。
また、 差分デプロイとなるため、仮に main ブランチにバグがある状態でも資材をリリースできる。他の開発との待ち合わせをほとんど意識しなくて良く、自分がリリースしたい時にリリースできる。

- スケジューラの撤廃
job を書いたり、tag や selector を意識するのはつらい。スケジュールjobを書かなくてよくするため、作られるモデルは view に限定した。

{{ dbt プロジェクトの構成の絵と、かくディレクトリのデプロイフローの図 }}

## ルール

ルールも作った

性能との戦い
- adhoc で作るモデルは view だけ
当たり前だけど table や incremental は dbt run のスケジュール実行がないと更新できない。性能面ではデメリットになる。これは、BIの機能を使って、ローカル抽出することで解決できた。

{{ 抽出の絵 }}

品質管理との戦い
- adhoc で作ったモデルは job からの参照禁止
リリースタイミングと品質の位置付けを分けるために、adhoc のテーブルとそうでないテーブルは一方通行とした。

{{ 一方通行のパイプラインの絵 }}

補足：adhoc のモデルを job から参照すると、リリースタイミングの違いによって、job の実行で view の中身が更新されてしまう。なので adhoc で書いたクエリは adhoc に閉じるよう制約を与えた。下流のテーブルは全て adhoc になる。

- primary key テストは必須
adhoc からさらに adhoc を作るなど、SQLの分割についてはルール無用とし、自由度を与えた。
最低限、ソースの変更などによってレコード重複が起きるケースを検知するため、モデルごとに primary key test は必須とした。
※ assert_value や reference など追加のテストは大歓迎


## この実装に至った経緯
### データマネジメント観点で守りたい要件

集計ミスを起こさないのではなく、間違っていた時にフォローできる状態を意識する。QCDのバランスが取れなくなった時に、修正できること。

- 最低一人の approve があるクエリであること
明らかにおかしなクエリや、全くテストのないクエリが動くのを防止したい。

- リポジトリにクエリがコミットされ、ソース管理ができていること。
不具合時、gitのコミットログから発生時期を調べたい。クエリに不具合があったら調べたい。

- リネージがたどれること
ソースデータの欠損など、障害時の影響調査を効率よく行いたい


### 諦める要件
すぐに分析するが、長期で運用しない前提。

- 性能
job の存在が大きなネック。性能や冪等性、依存関係は初心者には難しい。そこで job によるスケジュール更新をやめる。

- クエリ間での指標の定義ズレ
指標の定義を決める作業が大きなネック。既存でモニタリングしていた数値ロジックの確認や、参照すべきテーブルの精査などの作業が発生してしまう。そこで、クエリ間での定義ズレ問題に一旦目を瞑る。

- クエリ品質・長期的な保守性
共通処理の切り出しや SSoT といった概念は初学者には難しい。下手にマクロを作って共通処理を作っても、密結合になって信頼を落とすことも多い。そこで、モデリングの良し悪しには一旦目を瞑る。




## いつリファクタするのか
性能劣化、リソース超過、保守性の限界を迎えるとき。tobe 象というよりは、基本は課題ベースで修正を行なっていく。
- 性能劣化：view ではなく table や incremental を使いたくなるようなデータ量になったとき
- リソース超過：adhoc view は、BigQuery の場合、query too complex エラーが出てくる。このタイミングでリファクタリングを検討。
- 保守性の限界：求められるD要求に対して、実装工数が追いつかなくなったり、求められる品質に対して、集計ミスが多くなりすぎたとき、課題ベースでリファクタを行う。

## 実際の効果

### クエリのライフサイクル
小さい検証をいっぱいできる環境として良く機能した。分析は仮説検証の繰り返しでもあるので、なんとなく思いついたことを adhoc として作成しておいて、うまくいったらちゃんとモデリングし、そうでないものはそのまま削除する、といったサイクルは相性が良かった。

{{ アドホック => 修正・増築 => モデリングされたクエリ or 削除の絵 }}

### job のことを考えない設計
めちゃめちゃアドホッククエリが使われた。jobがないというのがかなり良い。jobは朝とかに混雑するので、混雑を避けるために時間を決める、とかの調整が発生しないのが良い。jobを作成するスキルを問わず、人気だった。
job の処理をカプセル化するというのは、 adhoc 以外にも適用余地がある。例えばワークフローエンジンの運用だけ別チームに切り出し、分析チームはクエリの作成に集中する、というような分担も良さそうだった。

### オンボーディングとしての adhoc
新規参画したメンバーのオンボーディングタスクに良かった。dbt を初めて触るという人にとって、まずは dbt 記法で書いて本番環境にテーブルを作ることができる体験は良い。

###  リファクタリングの難しさ
アドホッククエリのリファクタリングはあまり進まなかった。①そもそもアドホックで書いたクエリの50%くらいしか長期で使われていかない or みてる人が数人のニッチなテーブルになっていた。②一度アドホックで出すと、次も近いデリバリー感の要件が飛んできてしまい、リファクタリングの時間が取れなくなってしまった。※クオリティを重視するフェーズにないチームなのか、単に看過してるだけなのかは見定め中。

### adhoc ではない adhoc クエリ
adhoc の adhoc 参照は失敗だったかもしれない。元々単発の分析用途で提供していたが、 adhoc クエリで作った view を SSoT 的に再利用し始めるケースを止められなかった。
結果、アドホックな要件でないものも、adhoc の view を使いたいがために、adhoc として作成する、という状況に陥った。
adhoc view を再利用するようになったら、強制的にadhocから退場させるような仕組み、ルールを作る必要があった。

